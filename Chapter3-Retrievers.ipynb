{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Langchain Retrievers\n",
    "\n",
    "A retriever is an interface that returns documents based on an unstructured query input from a user. \n",
    "\n",
    "It is more general than a vector store and does not need to store documents, only to retrieve them. Retrievers can be used to create retrieval chains that retrieve documents and then pass them on.\n",
    "\n",
    "Vector stores can be used as the backbone of a retriever, but there are other types of retrievers as well. For our use case we are going to use a vector store based retriever.\n",
    "\n",
    "Different types of Langchain Retrievers can be found here: [ Langchain_Retrievers ](https://python.langchain.com/docs/modules/data_connection/retrievers)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2262, which is longer than the specified 1000\n",
      "Created a chunk of size 1080, which is longer than the specified 1000\n",
      "Created a chunk of size 1031, which is longer than the specified 1000\n",
      "Created a chunk of size 1047, which is longer than the specified 1000\n",
      "Created a chunk of size 2554, which is longer than the specified 1000\n",
      "Created a chunk of size 3139, which is longer than the specified 1000\n",
      "Created a chunk of size 2846, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "#! pip install faiss-cpu\n",
    "import os, getpass\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass()\n",
    "\n",
    "\n",
    "web_document = WebBaseLoader(\"https://www.rfc-editor.org/rfc/rfc6517.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "web_document_chunks = text_splitter.split_documents(web_document)\n",
    "faiss_db = FAISS.from_documents(web_document_chunks, OpenAIEmbeddings())\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell , we are loading a document from the web , splitting it into chunks and then indexing the data using a vectorstore. we have already covered these steps in detail in our previous Jupyter Notebook \"Introduction to Vectorstores\"\n",
    "\n",
    "The only difference here though is we are using another very popular vectorstore named \"FAISS\".\n",
    "\n",
    "With all the necessary steps completed, creating a retriever is fairly easy with just two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = faiss_db.as_retriever()\n",
    "query = \"What is the document about?\"\n",
    "\n",
    "#retriever.invoke(query)\n",
    "\n",
    "# from langchain.retrievers import MultiQueryRetriever\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# chat_model = ChatOpenAI()\n",
    "# multi_query_retriever = MultiQueryRetriever.from_llm(retriever=faiss_db.as_retriever(), llm=chat_model)\n",
    "# docs = multi_query_retriever.invoke(query)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note here is that a retriever does not get response from a LLM. Its function is primarily to retrieve most relevant documents from a data source based on the user query.\n",
    "\n",
    "In order to create a LLM response to a user query we have to construct a prompt and then pass in the prompt along with the retrived documents from a retriever to a LLM; and we do this by creating a \"Retrieval chain\".\n",
    "\n",
    "The entire flow of this process from ingesting a document , splitting , vectorizing and passing relevant data to LLM is known as \"RAG - Retrieval Augmented Generation\"\n",
    "\n",
    "We have already seen under \"quick_introduction\" notebook that langchain uses LCEL (Langchain Expression Language) to create a chain.\n",
    "\n",
    "chain = llm | prompt | output_parser \n",
    "\n",
    "Now, LCEL is great for constructing simple chains as shown above. For retrieval type of chains which involves adding an extra piece i.e a retriever to the chain, LangChain offers a higher-level constructor method to simplify creating a retrieval based chains. However, all that is being done under the hood is constructing a chain with LCEL.\n",
    "\n",
    "For RAG systems, Langchain offers \"create_retrieval_chain\" constructor method. This chain takes in a user inquiry, which is then passed to the retriever to fetch relevant documents. Those documents (and original inputs) are then passed to an LLM to generate a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is about multicast VPN proposals and implementations.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\"  )\n",
    "\n",
    "#Another way of using promtptemplates\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     SystemMessagePromptTemplate.from_template(\n",
    "#         \"\"\"Answer the following user question based only on the provided context:\n",
    "# <context>\n",
    "# {context}\n",
    "# </context> \"\"\"),\n",
    "# HumanMessagePromptTemplate.from_template(f\"Question: {input}\")])\n",
    "\n",
    "chat_model_chain = chat_model | prompt\n",
    "document_chain = create_stuff_documents_chain(chat_model, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"what document is this about?\"})\n",
    "\n",
    "print(response['answer'])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Conversational Retrieval Chain\n",
    "\n",
    "The chain we created above, can answer user questions related to the context of the data source provided. However , the chain does not track any history of prior conversations or questions that are asked.\n",
    "\n",
    "Every question is treated as a new question and is answered without any context or prior knowledge of conversations that happed earlier with the user. This is a problem when you are trying to build an chatbot app. For a chatbot app it is necessary to have history of the previous conversations when answering any new user questions for accurate results.\n",
    "\n",
    "The key is to save the user and the LLM chat history as a variable or entity in our prompt. The new chain will then take in the most recent input (input) and the conversation history (chat_history) and use an LLM to generate a search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'do you remember my last question?',\n",
       " 'chat_history': [AIMessage(content='{\\'input\\': \\'what is the document about?\\', \\'chat_history\\': [], \\'context\\': [Document(page_content=\"This document is subject to BCP 78 and the IETF Trust\\'s Legal\\\\n   Provisions Relating to IETF Documents\\\\n   (http://trustee.ietf.org/license-info) in effect on the date of\\\\n   publication of this document.  Please review these documents\\\\n   carefully, as they describe your rights and restrictions with respect\\\\n   to this document.  Code Components extracted from this document must\\\\n   include Simplified BSD License text as described in Section 4.e of\\\\n   the Trust Legal Provisions and are provided without warranty as\\\\n   described in the Simplified BSD License.\\\\n\\\\nTable of Contents\", metadata={\\'source\\': \\'https://www.rfc-editor.org/rfc/rfc6517.txt\\'}), Document(page_content=\\'The aim of this document is to leverage the already expressed\\\\n   requirements [RFC4834] and study the properties of each approach to\\\\n   identify mechanisms that are good candidates for being part of a core\\\\n   set of mandatory mechanisms that can be used to provide a base for\\\\n   interoperable solutions.\\\\n\\\\n   This document goes through the different building blocks of the\\\\n   solution and concludes which mechanisms an implementation is required\\\\n   to implement.  Section 7 summarizes these requirements.\\\\n\\\\n   Considering the history of the multicast VPN proposals and\\\\n   implementations, it is also useful to discuss how existing\\\\n   deployments of early implementations [RFC6037] [MVPN] can be\\\\n   accommodated and provide suggestions in this respect.\\\\n\\\\n2.  Terminology\\', metadata={\\'source\\': \\'https://www.rfc-editor.org/rfc/rfc6517.txt\\'}), Document(page_content=\\'Internet Engineering Task Force (IETF)                     T. Morin, Ed.\\\\nRequest for Comments: 6517                       France Telecom - Orange\\\\nCategory: Informational                            B. Niven-Jenkins, Ed.\\\\nISSN: 2070-1721                                                       BT\\\\n                                                               Y. Kamite\\\\n                                                      NTT Communications\\\\n                                                                R. Zhang\\\\n                                                          Alcatel-Lucent\\\\n                                                              N. Leymann\\\\n                                                        Deutsche Telekom\\\\n                                                                N. Bitar\\\\n                                                                 Verizon\\\\n                                                           February 2012\\', metadata={\\'source\\': \\'https://www.rfc-editor.org/rfc/rfc6517.txt\\'}), Document(page_content=\\'This document is a product of the Internet Engineering Task Force\\\\n   (IETF).  It represents the consensus of the IETF community.  It has\\\\n   received public review and has been approved for publication by the\\\\n   Internet Engineering Steering Group (IESG).  Not all documents\\\\n   approved by the IESG are a candidate for any level of Internet\\\\n   Standard; see Section 2 of RFC 5741.\\\\n\\\\n   Information about the current status of this document, any errata,\\\\n   and how to provide feedback on it may be obtained at\\\\n   http://www.rfc-editor.org/info/rfc6517.\\\\n\\\\nMorin, et al.                 Informational                     [Page 1]\\\\n\\\\x0c\\\\nRFC 6517            Multicast VPN Mandatory Features       February 2012\\\\n\\\\n\\\\nCopyright Notice\\\\n\\\\n   Copyright (c) 2012 IETF Trust and the persons identified as the\\\\n   document authors.  All rights reserved.\\', metadata={\\'source\\': \\'https://www.rfc-editor.org/rfc/rfc6517.txt\\'})], \\'answer\\': \\'The provided context is about RFC 6517, which discusses multicast VPN mandatory features. It aims to identify mechanisms that could be part of a core set of mandatory mechanisms for interoperable solutions. The document also mentions the consensus of the IETF community and the approval for publication by the IESG.\\'}')],\n",
       " 'context': [Document(page_content='We can see that the \"last receiver leaves\" question is a part of the\\n   work that the C-multicast routing building block has to address, and\\n   the different approaches significantly differ.  The different\\n   approaches for handling C-multicast routing can indeed result in a\\n   different amount of processing and how this processing is spread\\n   among the different functions.  These differences can be better\\n   estimated by quantifying the amount of message processing and state\\n   maintenance.', metadata={'source': 'https://www.rfc-editor.org/rfc/rfc6517.txt'}),\n",
       "  Document(page_content='Morin, et al.                 Informational                    [Page 25]\\n\\x0c\\nRFC 6517            Multicast VPN Mandatory Features       February 2012\\n\\n\\n      advertising this route anymore.  Similarly, a route reflector that\\n      had advertised this route to its client PEs before will withdraw\\n      this route when its (other) client PEs and its route reflectors\\n      peers are no longer advertising this route.  In this context, the\\n      \"did the last receiver leave?\" question can be said to be answered\\n      by the route reflector(s).\\n\\n      Furthermore, the BGP route distribution can leverage more than one\\n      route reflector: if multiple route reflectors are used with PEs\\n      being distributed (as clients) among these route reflectors, the\\n      \"did the last receiver leave?\" question is partly answered by each\\n      of these route reflectors.', metadata={'source': 'https://www.rfc-editor.org/rfc/rfc6517.txt'}),\n",
       "  Document(page_content='BGP-based C-multicast routing\\n      When BGP-based procedures are used for C-multicast routing, if no\\n      BGP route reflector is used, the \"did the last receiver leave?\"\\n      question is answered by having the upstream PE maintain an up-to-\\n      date list of the PEs that are joined to the tree, thus making it\\n      possible to instantly know the answer to the \"did the last\\n      receiver leave?\" question whenever a PE leaves the said multicast\\n      tree.\\n\\n      However, when a BGP route reflector is used (which is expected to\\n      be the recommended approach), the role of maintaining an updated\\n      list of the PEs that are part of a said multicast tree is taken\\n      care of by the route reflector(s).  Using BGP procedures, a route\\n      reflector that had advertised a C-multicast Source Tree Join route\\n      for a said (C-S,C-G) to other route reflectors before will\\n      withdraw this route when there is no of its clients PEs', metadata={'source': 'https://www.rfc-editor.org/rfc/rfc6517.txt'}),\n",
       "  Document(page_content='Internet Engineering Task Force (IETF)                     T. Morin, Ed.\\nRequest for Comments: 6517                       France Telecom - Orange\\nCategory: Informational                            B. Niven-Jenkins, Ed.\\nISSN: 2070-1721                                                       BT\\n                                                               Y. Kamite\\n                                                      NTT Communications\\n                                                                R. Zhang\\n                                                          Alcatel-Lucent\\n                                                              N. Leymann\\n                                                        Deutsche Telekom\\n                                                                N. Bitar\\n                                                                 Verizon\\n                                                           February 2012', metadata={'source': 'https://www.rfc-editor.org/rfc/rfc6517.txt'})],\n",
       " 'answer': 'I\\'m sorry, but I cannot provide an answer to the question \"<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x7fb914366490>>\" as it seems to be related to the input method in a programming context. If you have any other question or need assistance, feel free to ask.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List\n",
    "\n",
    "conversational_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"\"\"Answer the following user question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context> \"\"\"),\n",
    "HumanMessagePromptTemplate.from_template(f\"Question: {input}\"),\n",
    "MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(chat_model, conversational_prompt)\n",
    "\n",
    "chat_history: List[BaseMessage] = []\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\n",
    "    \"input\": \"what is the document about?\",\n",
    "    \"chat_history\":chat_history})\n",
    "\n",
    "chat_history = [AIMessage(content=str(response))]\n",
    "\n",
    "retrieval_chain.invoke({\n",
    "    \"input\": \"do you remember my last question?\",\n",
    "    \"chat_history\":chat_history})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a27b9a44dddb1eedec426fa966a46221b6963a983add3b1046110dc32ee2722c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
